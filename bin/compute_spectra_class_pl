#!/usr/bin/env python
import sys
import polars as pl

MAPPING = {
    '0/0': '0',
    '0|0': '0',
    '1|0': '1',
    '0|1': '1',
    '1|1': '1',
    '1/1': '1',
    '0/1': '1'
}

def parse_args():
    import argparse
    # Argument definition
    parser = argparse.ArgumentParser()
    parser.add_argument("-i", "--input", metavar = 'input.tsv', type = str, help = 'Input dataframe from bcftools split-vep, with fields CHROM, POS, mutation_type, Consequence and genotypes',\
                            dest = 'input', required = True)
    parser.add_argument("-k", "--kmers", metavar = 'kmers.txt', type = str, help = 'Kmers list (with header)',\
                            dest = 'kmer', required = False, default = None)
    parser.add_argument("-c", "--csqs", metavar = 'csqs.txt', type = str, help = 'Dataset of VEP consequences and impacts',\
                            dest = 'csqs', required = False, default = None)
    parser.add_argument("-H", "--header", metavar = 'header.txt', type = str, help = 'Input dataframe header',\
                            dest = 'header', required = True, default = None)
    parser.add_argument("-o", "--out", metavar = 'prefix', type = str, help = 'Output file.',\
                            dest = 'out', required = False, default = "myanc.fa")
    parser.add_argument("--all", action='store_true', help = 'Add missing change-by-consequence combinations to the output dataframe.')
    return parser.parse_args()


def main():
    """Run entry point."""
    # Parse arguments
    args = parse_args()

    # import header first
    header = open(args.header).read().splitlines()
    
    # Import data
    df = pl.read_csv(args.input, has_header=False, new_columns=header, separator='\t')

    # Drop null columns
    df = df[[s.name for s in df if not (s.null_count() == df.height)]]

    # Drop unnecessary columns
    df = df.select(pl.col("*").exclude("CHROM", "POS"))

    # Remap the data to whether they have a derived allele or not
    df = df.select(pl.all().replace(MAPPING))

    # Change data type to int
    df = df.cast({col:int for col in header[4:]})

    # Summarize data
    df = df.group_by(('CHANGE', 'CSQ')).sum()

    # If store all requested, add missing consequences
    if args.all:
        # Create minimal levels of factors to facilitate future merging.
        # first load all kmers
        kmers = open(args.kmers).read().splitlines()[1:]
        # then load all consequences
        csqs = pl.read_csv(args.csqs, has_header=False, new_columns=['CSQ', 'IMPACT'], separator='\t')
        # Drop the impact
        csqs = csqs.select(pl.col(['CSQ']).unique().implode())
        # Add kmers, and expand them to find all consequence-by-kmer conbo
        csqs = csqs.with_columns(CHANGE = pl.lit(kmers))[['CHANGE', 'CSQ']]
        csqs = csqs.explode('CHANGE').explode('CSQ')
        # Add them to the DF
        df = pl.concat((
                df[['CHANGE', 'CSQ']],
                csqs
            ))

    # Add missing levels
    # First, we concatenate the full consequence-by-kmer with the output
    df = (
        df
            .select(pl.col(['CHANGE', 'CSQ']).unique().implode())  # second, we find the unique values for the two level columns and implode them
            .explode('CHANGE')  # third, we explode the values once at the time, creating every combo of vals
            .explode('CSQ')
            .join(df, how='left', on=['CHANGE','CSQ']) # fourth, we add back the initial values
            .fill_null(0)  # finally, we set missing to zero
        )

    # Save data
    df.write_csv(args.out, separator='\t')

    sys.stderr.write( "All done\n" )


if __name__ == "__main__":
    main()
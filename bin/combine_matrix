#!/usr/bin/env python
import os

import numpy as np


def parse_args():
    import argparse
    # Argument definition
    parser = argparse.ArgumentParser()
    parser.add_argument("-i", "--input", metavar = 'input_dir/', type = str, help = 'Input dir with multiple files to combine',\
                            dest = 'input', required = True)
    parser.add_argument("-o", "--out", metavar = 'prefix', type = str, help = 'Output file.',\
                            dest = 'out', required = False, default = "out.tsv")
    parser.add_argument("--large_genome", action="store_true", help="The genome is larger than 4Gb")

    return parser.parse_args()


def import_table(fname, large=False):
    """Import dataframe."""
    dataset = {}
    dtype = "uint64" if large else "uint32"
    with open(fname) as input:
        header = input.readline()
        for line in input:
            line = line.strip().split()
            if 'CSQ' in header.split():
                dataset[line[0]] = {line[1]: np.array(line[2:], dtype=dtype)}
            else:
                dataset[line[0]] = np.array(line[1:], dtype=dtype)
    return header, dataset


def main():
    """Run entry point."""
    # Parse arguments
    args = parse_args()

    # Get input files
    infiles = [i for i in os.listdir(f'{args.input}/') if i.endswith('.tsv')]

    # Check if dataframe is empty
    if not infiles:
        return 1

    # concatenate multiple 
    # Use less memory than before, but probably slower
    header, dataset = import_table(f'{args.input}/{infiles[0]}', large=args.large_genome)
    if len(infiles) > 1:
        for n in range(1, len(infiles)):
            h2, df = import_table(f'{args.input}/{infiles[n]}', large=args.large_genome)
            if h2 != header:
                raise Exception("Data have unmatched column order.")
            for key, vals in df.items():
                if key not in dataset:
                    dataset[key] = vals
                else:
                    dataset[key] += vals

    # Save data
    with open(args.out, 'w') as outfile:
        outfile.write(header)
        for key, vals in dataset.items():
            values = '\t'.join(vals.astype('U32'))
            if isinstance(key, tuple):
                keys = '\t'.join(key)
                out_string = f"{keys}\t{values}\n"
            else:
                out_string = f"{key}\t{values}\n"
            outfile.write(out_string)


if __name__ == "__main__":
    main()
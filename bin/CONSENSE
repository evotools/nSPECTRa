#!/usr/bin/env python
from collections import Counter
import logging
import os

import polars as pl
from pysam import FastaFile


def parse_args():
    """Define arguments."""
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument(
        "-b",
        "--bed",
        metavar="ancestral_bed.bed",
        type=str,
        help="Input ancestral bed file",
        dest="bed",
        required=True,
    )
    parser.add_argument(
        "-f",
        "--fasta",
        metavar="reference.fasta",
        type=str,
        help="Input fasta file",
        dest="fasta",
        required=True,
    )
    parser.add_argument(
        "-r",
        "--region",
        metavar="str",
        type=str,
        help="Sequence ID to process",
        dest="region",
        required=True,
    )
    parser.add_argument(
        "-t",
        "--threads",
        metavar="N",
        type=int,
        help="Number of threads; defaults all of them",
        dest="threads",
        required=False,
    )
    parser.add_argument(
        "-g", "--greedy", action="store_true", help="Run in greedy mode.", dest="greedy"
    )
    parser.add_argument(
        "-o",
        "--out",
        metavar="prefix",
        type=str,
        help="Output file.",
        dest="out",
        required=False,
        default="myanc.fa",
    )
    return parser.parse_args()


# Define consensus allele
def consense_query(input_alleles):
    input_alleles = input_alleles.upper().replace("N", "-").replace(".", "-")
    ref = input_alleles[0]
    cnt_full = Counter(input_alleles)
    cnt_alts = Counter(input_alleles[1:])
    candidate = cnt_alts.most_common()
    second = cnt_full.most_common()
    # Refine logic
    if ref == "-" or list(cnt_alts.keys()) == ["-"] or list(cnt_full.keys()) == ["-"]:
        return "-"
    if len(candidate) == 1:
        return candidate[0][0]
    if len(candidate) >= 2 and candidate[0][1] > candidate[1][1]:
        return candidate[0][0] if len(candidate) == 2 else candidate[0][0].lower()
    if len(candidate) >= 2 and second[0][1] > second[1][1]:
        return second[0][0].lower()
    return "-"


def memory_group(sorted_df):
    """This function has a memory efficient grouping of the data, if the inputs are sorted."""
    result = []
    current_group = None
    current_vals = []
    # Iterate through the DataFrame
    for row in sorted_df.iter_rows(named=True):
        group = row["start"]
        if current_group is None:
            current_group = group
        if group == current_group:
            current_vals.append(row["val"])
        else:
            result.append((current_group, "".join(current_vals)))
            current_group = group
            current_vals = [row["val"]]
    # Don't forget to add the last group
    if current_group is not None:
        result.append((current_group, "".join(current_vals)))
    # Convert result to a DataFrame
    return pl.DataFrame(result, schema=["start", "val"])


# Main function
def main():
    # Import arguments
    args = parse_args()

    # Define logger
    global _log_name
    _log_name = 'CONSENSE'
    logging.basicConfig(
        format="[%(asctime)s - %(name)s] %(message)s",
        datefmt="%H:%M:%S",
        level=logging.INFO,
    )
    logger = logging.getLogger(_log_name)

    # Define thread pool
    if args.threads:
        logger.info(f"Setting threads to: {args.threads}")
        os.environ["POLARS_MAX_THREADS"] = f"{args.threads}"

    # Instatiate reference
    reference = FastaFile(args.fasta)

    # Add reference bases
    logging.info("Add reference")
    reference = pl.DataFrame(
        {
            "chrom": args.region,
            "start": range(0, len(reference[args.region])),
            "ref": tuple(reference[args.region]),
        }
    )

    # Load the BED file
    logging.info("Loading vertical")
    df = pl.read_csv(
        args.bed,
        has_header=False,
        separator="\t",
        new_columns=["start", "val"],
    )

    # Combine bases for same position
    if args.greedy:
        logging.info("Grouping data (greedy)")
        df = df.group_by("start", maintain_order=True).agg(pl.col("val").str.concat(""))
    else:
        logging.info("Grouping data (memory)")
        df = memory_group(df)
        # df = (
        #     df.group_by("start", maintain_order=True)
        #     .agg(pl.col("val"))
        #     .with_columns(
        #         val=pl.col("val").map_elements(
        #             # lambda x: "".join(x), return_dtype=str, strategy="threading"
        #             pl.col("val").map_elements(lambda x: "".join(x), return_dtype=pl.Utf8, strategy="threading").alias("val")
        #         )
        #     )
        # )

    # Sort positions
    logging.info("Sorting")
    df = (
        df
        .with_columns(
            chrom=pl.lit(args.region)
        )
        .select(['chrom', 'start', 'val'])
    )


    # Add reference base, then drop the ref col
    df = (
        df
        .join(reference, on=("chrom", "start"), how="left")
        .with_columns(val=pl.concat_str(pl.col("ref"), pl.col("val")))
        .drop("ref")
    )

    # Get consensed value
    logging.info("Run consensus")
    df = df.with_columns(
        con=pl.col("val").map_elements(
            lambda x: consense_query(x), return_dtype=str, strategy="threading"
        ),
        end=pl.col("start") + 1
    ).select(['chrom', 'start', 'end', 'val', 'con'])

    # Save data
    df.write_csv(args.out, separator="\t", include_header=False)
    logging.info("Done")
    return 0


if __name__ == "__main__":
    main()

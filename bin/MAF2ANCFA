#!/usr/bin/env python

#####
#
# Created by: Andrea Talenti
# Date: 20 Feb, 2020
# 
# Script that create a fasta or bed files 
# the initial reference-based maf files.
# MAF files have to be created starting from
# the output hal file generated from CACTUS.
# Conversion from hal to maf with hal2maf tool. 
#
#####
import numpy as np
import sys, os
revert = {"A":"T", "T":"A", "C":"G","G":"C", 
            "a":"t", "t":"a", "c":"g", "g":"c"}

# Define reference and target sequences
def get_ref(lines, seq):
    rname = lines[0].strip().split()[1].split(".")[0]           # Get reference names
    if seq is not None:                                         # If target sequence is provided, focus on that.
        references = [line for line in lines if seq in line.split()[1]]
        queries = [line for line in lines if "Anc" in line or "Inner" in line]
    else:                                                       # Otherwise keep all that share the first (ref) line spp.
        references = [line for line in lines if "Anc" not in line and "Inner" not in line]
        queries = [line for line in lines if "Anc" in line or "Inner" in line]
    return references, queries                                 # Return reference-spp name and list of ref and target sequences.

# Executor module to process one reference sequence out of the options
def executor(reference, queries):
    ref = reference.strip().split()
    refChrom, refBpi, refStrand, refLen, refseq = ref[1], int(ref[2]), ref[4], int(ref[5]), np.array(list(ref[6]))
    mystr = '{}\t{}\t{}\n'
    # if refStrand == "-":
    #     refBpi = refLen - refBpi - sum(refseq != "-")
    #     refseq = np.array([ revert.get(i, i) for i in refseq ])
    idxNonRef = refseq != "-"
    newseq = np.full(sum(idxNonRef), "-")
    for query in queries:
        seq = np.array(list(query.strip().split()[6]))
        # if query.split()[4] == "-": 
        #     seq = np.array([ revert.get(i, i) for i in seq ])
        seq = seq[idxNonRef]
        idx = seq != "-"
        newseq[idx] = seq[idx] 
    return mystr.format(refChrom, refBpi, ''.join(newseq))


# High memory worker (keep in memory)
def worker(inputs):
    # Extract inputs from tuple
    lines, ctr, seq = inputs
    # Get sequences information
    references, queries = get_ref(lines, seq)
    finalStr = ""
    if len(references) == 0: return finalStr
    result = ""
    reference = references[0]
    result += executor(reference, queries)
    if ctr % 10000 == 0:
        sys.stderr.write( "Processed chunk {}\n".format(ctr) )
    return result.strip()


def reader(args):
    lines = []
    blocks = []
    infile = open(args.maf)
    for line in infile:
        if "#" in line:
            continue
        elif line[0] == "a": 
            continue
        elif line[0] == "s":
            lines.append(line)
            continue
        elif line.strip() == "" and len(lines) != 0:
            blocks.append(lines)
            lines = []
        else:
            lines = []
    return blocks
    


def single_proc(funct, chunk, seq):
    return [funct((block, n, seq)) for n, block in enumerate(chunk)]


def multi_proc(funct, chunk, seq, nthreads):
    from multiprocessing import Pool
    pool = Pool(nthreads)
    return pool.map(funct, zip(chunk,list(range(0, len(chunk))), [seq for i in range(0, len(chunk))] ) )


def sort(dat):
    dat = dat.strip().split('\n')
    sys.stderr.write("Removing duplicates...\n")
    dat = list(set(dat))
    try: 
        seqLength = sum([len(d.split()[2]) for d in dat])
    except:
        print(dat[0])
        sys.exit()
    dat = [[int(i) if i.isdigit() else i for i in d.split()] for d in dat]
    sys.stderr.write("Number of bases in the sequence is: {}\n".format(seqLength))
    dat = sorted(dat)
    return dat

def dat2fasta_dev(data, outfile, args):
    tmpname = data[0][0]
    if args.drop_prefix is not None:
        tmpname = tmpname.replace(args.drop_prefix + ".", "")
    maxV = max([i[2] for i in data if i[0] == tmpname])
    sys.stderr.write("Highest bp value covered is {} (0-based value)\n".format(maxV))
    tmpseq = np.full(maxV + 1, "-")
    outfile.write(">{}\n".format( tmpname  ))
    for seq in data:
        if seq[0] != tmpname:
            [outfile.write( "{}\n".format(''.join(tmpseq[i:i+60])) ) for i in range(0, tmpseq.shape[0], 60)]
            tmpname = seq[0]
            maxV = max([i[2] for i in data if i[0] == tmpname])
            tmpseq = np.full(maxV + 1, "-")
            outfile.write(">{}\n".format( '.'.join( tmpname.split('.')[1:] ) ))
            continue
        try:
            tmpseq[ seq[1] : (seq[1] + len(seq[3])) ] = np.array(list(seq[3]))
        except:
            print(seq[0:3])
            print(seq[3])
            print(len(seq[3]))
            sys.exit()
        
    [outfile.write( "{}\n".format(''.join(tmpseq[i:i+60])) ) for i in range(0, tmpseq.shape[0], 60)]
    return None


def dat2bed(dat, of, args):
    for d in dat:
        if args.drop_prefix is not None:
            d[0] = d[0].replace(args.drop_prefix + ".", "")
        of.write("{}\t{}\t{}\t{}\n".format(d[0], d[1], d[2], d[3]))

def createEndBp(dat):
    endBps = [[d[0], d[1], d[1] + len(d[2]), d[2]] for d in dat]
    return endBps


def Pipeline(blocks, args):
    if args.seq is not None:
        sys.stderr.write("Limiting to {}\n".format(args.seq))
    if args.threads == 1:
        sys.stderr.write("Start processing the data\n")
        dat = single_proc(worker, blocks, args.seq)
    else:
        sys.stderr.write("Start processing the data using {} threads.\n".format(args.threads) )
        dat = multi_proc(worker, blocks, args.seq, args.threads)
    # Sort sequences by base
    dat = createEndBp(sort('\n'.join(dat)))
    
    # Create output
    if "fasta" in args.ofmt or "fa" in args.ofmt:
        fmt = "fasta"
        # Create temporary file
        sys.stderr.write("Save fasta file...\n")
        if args.outname == "stdout" and "," not in args.ofmt:
            of = sys.stdout
        else:
            if "stdout" in args.outname:
                sys.stderr.write("Cannot print to stdout if multiple output formats are required\n")
                args.outname = "fastafile"
            of = open( "{}.{}".format(args.outname, fmt), "w" )
        dat2fasta_dev(dat, of, args)
        of.close()
    if "bed" in args.ofmt:
        fmt = "bed"
        sys.stderr.write("Save bed file...\n")
        # Create temporary file
        if args.outname == "stdout" and "," not in args.ofmt:
            of = sys.stdout
        else:
            if "stdout" in args.outname:
                sys.stderr.write("Cannot print to stdout if multiple output formats are required\n")
                args.outname = "bedfile"
            of = open( "{}.{}".format(args.outname, fmt), "w" )
        dat2bed(dat, of, args)
        of.close()
    return 0


def parse_args():
    import argparse
    # Argument definition
    parser = argparse.ArgumentParser()
    parser.add_argument("-m", "--maf", metavar = 'maffile.maf', type = str, help = 'Input alignments',\
                            dest = 'maf', required = True)
    parser.add_argument("-t", "--threads", metavar = '1', type = int, help = 'Number of threads to use',\
                            dest = 'threads', required = False)
    parser.add_argument("-s", "--seq", metavar = 'tgtseq', type = str, help = 'Target sequence to compute ancestral allele',\
                            dest = 'seq', required = False, default = None)
    parser.add_argument("-d", "--drop_prefix", metavar = 'prefix', type = str, help = 'Drop prefix from sequence ID',\
                            dest = 'drop_prefix', required = False, default = None)
    parser.add_argument("-o", "--out", metavar = 'prefix', type = str, help = 'Output file prefix.',\
                            dest = 'outname', required = False, default = "myanc")
    parser.add_argument("-O", "--OutFmt", metavar = 'fasta/bed', type = str, help = 'Output file format (fasta/bed).',\
                            dest = 'ofmt', required = False, default = "fasta")
    
    return parser.parse_args()

def parse_fasta_length(fasta):
    values = {}
    for line in open(fasta):
        if ">" in line:
            ctgid = line.strip().replace(">", "").split()[0]
            values[ctgid] = 0
            continue
        values[ctgid] += len(line.strip())
    return values

def main():
    import time
    from subprocess import Popen

    args = parse_args()
    # Set environment number of variables
    os.environ["OMP_NUM_THREADS"] = "1"

    sys.stderr.write("Reading alignments blocks and chunking it...\n")
    blocks = reader(args)

    s_time = time.time()
    Pipeline(blocks, args)

    sys.stderr.write("All done in {}s\n".format(time.time() - s_time))
    return 0


if __name__ == "__main__":
    main()

    
